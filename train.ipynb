{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T16:37:25.686290Z",
     "start_time": "2024-06-12T16:37:23.224828Z"
    }
   },
   "source": [
    "# 1. Import necessary libraries\n",
    "from ultralytics import YOLO # Here we import YOLO\n",
    "import yaml                  # for yaml files\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Extract & convert\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "def extract_frames(video_path, output_folder, no_labels=False):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_path = os.path.join(output_folder, f'frame_{count:04d}.jpg')\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        count += 1\n",
    "    cap.release()\n",
    "    return count\n",
    "\n",
    "def convert_bbox_format(bbox, img_width, img_height):\n",
    "    x_min, y_min, width, height = bbox\n",
    "    x_center = (x_min + width / 2) / img_width\n",
    "    y_center = (y_min + height / 2) / img_height\n",
    "    width /= img_width\n",
    "    height /= img_height\n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "def convert_labels_json(json_path, frame_folder, class_mapping):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    categories = {cat['id']: class_mapping[cat['name']] for cat in data['categories']}\n",
    "    images = {img['id']: img for img in data['images']}\n",
    "    annotations = data['annotations']\n",
    "\n",
    "    for ann in annotations:\n",
    "        image_info = images[ann['image_id']]\n",
    "        frame_index = image_info['id']  # Assuming image_id corresponds to frame index\n",
    "        frame_file = os.path.join(frame_folder, f'frame_{frame_index:04d}.jpg')\n",
    "        if not os.path.exists(frame_file):\n",
    "            continue\n",
    "\n",
    "        img_width = image_info['width']\n",
    "        img_height = image_info['height']\n",
    "        bbox = ann['bbox']\n",
    "        class_id = categories[ann['category_id']]  # YOLO class IDs start from 0\n",
    "\n",
    "        x_center, y_center, width, height = convert_bbox_format(bbox, img_width, img_height)\n",
    "\n",
    "        yolo_label = f\"{class_id} {x_center} {y_center} {width} {height}\\n\"\n",
    "\n",
    "        output_label_file = frame_file.replace('.jpg', '.txt')\n",
    "        with open(output_label_file, 'w') as label_file:\n",
    "            label_file.write(yolo_label)\n",
    "\n",
    "base_path = './Gun_Action_Recognition_Dataset'\n",
    "categories = ['Handgun', 'Machine_Gun', 'No_Gun']\n",
    "class_ids = {'Handgun': 0, 'Machine_Gun': 1, 'No_Gun': 2}\n",
    "\n",
    "for category in categories:\n",
    "    category_path = os.path.join(base_path, category)\n",
    "    for subdir in os.listdir(category_path):\n",
    "        subdir_path = os.path.join(category_path, subdir)\n",
    "        if os.path.isdir(subdir_path):  # Check if the subdir_path is a directory\n",
    "            video_path = os.path.join(subdir_path, \"video.mp4\")\n",
    "            frame_folder = os.path.join(subdir_path, 'frames')\n",
    "            os.makedirs(frame_folder, exist_ok=True)\n",
    "\n",
    "            print(f\"Processing video: {video_path}\")\n",
    "            print(f\"Frame folder: {frame_folder}\")\n",
    "\n",
    "            # Estrarre i frame\n",
    "            extract_frames(video_path, frame_folder, no_labels=(category == 'No_Gun'))\n",
    "\n",
    "            # Convertire le annotazioni solo se non Ã¨ 'No_Gun'\n",
    "            if category != 'No_Gun':\n",
    "                json_path = os.path.join(subdir_path, 'label.json')\n",
    "                convert_labels_json(json_path, frame_folder, class_ids)\n",
    "        else:\n",
    "            print(f\"!!!!!!!!!!!!!!!!Skipping non-directory item: {subdir_path}\")\n"
   ],
   "id": "384a1cdeb02fbe10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T16:37:40.010179Z",
     "start_time": "2024-06-12T16:37:40.006968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "\n",
    "data = {'train': './train',\n",
    "    'val': './val',\n",
    "    'test': './test',\n",
    "    'nc': 2,  # Numero di classi\n",
    "    'names': ['Handgun', 'Machine_Gun']\n",
    "}\n",
    "\n",
    "# Write odometer_dataset.yaml file\n",
    "with open('guns_dataset.yaml', 'w') as file:\n",
    "    yaml.dump(data, file)"
   ],
   "id": "a940af25ed175d27",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T09:15:45.309876Z",
     "start_time": "2024-06-04T09:15:45.295004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "def create_dirs(base_path):\n",
    "    for dir_name in ['train', 'val', 'test']:\n",
    "        os.makedirs(os.path.join(base_path, dir_name, 'images'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(base_path, dir_name, 'labels'), exist_ok=True)\n",
    "\n",
    "\n",
    "def copy_files(src, dst, files):\n",
    "    for f in files:\n",
    "        src_file = os.path.join(src, f)\n",
    "        dst_file = os.path.join(dst, f)\n",
    "        shutil.copy(src_file, dst_file)\n",
    "\n",
    "\n",
    "def split_dataset(base_path, split_ratios=(0.7, 0.2, 0.1)):\n",
    "    assert round(sum(split_ratios), 10) == 1, \"The split ratios must sum to 1.\"\n",
    "    create_dirs(base_path)\n",
    "\n",
    "    categories = ['Handgun', 'Machine_Gun', 'No_Gun']\n",
    "    all_data = []\n",
    "\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(base_path, category)\n",
    "        subfolders = [f for f in os.listdir(category_path) if os.path.isdir(os.path.join(category_path, f))]\n",
    "\n",
    "        for subfolder in subfolders:\n",
    "            info = subfolder.split('_')\n",
    "            camera = info[1]\n",
    "            place = info[2]\n",
    "            subject = info[3]\n",
    "            brightness = info[4]\n",
    "\n",
    "            frames_path = os.path.join(category_path, subfolder, 'frames')\n",
    "            if not os.path.exists(frames_path):\n",
    "                continue\n",
    "\n",
    "            images = [f for f in os.listdir(frames_path) if f.endswith('.jpg')]\n",
    "            labels = [f for f in os.listdir(frames_path) if f.endswith('.txt')]\n",
    "\n",
    "            all_data.append({\n",
    "                'category': category,\n",
    "                'folder': subfolder,\n",
    "                'frames': frames_path,\n",
    "                'images': images,\n",
    "                'labels': labels,\n",
    "                'subject': subject,\n",
    "                'brightness': brightness,\n",
    "                'camera': camera,\n",
    "                'place': place\n",
    "            })\n",
    "\n",
    "    random.shuffle(all_data)\n",
    "\n",
    "    def split_data_by_feature(data, split_ratios):\n",
    "        feature_groups = defaultdict(list)\n",
    "        for item in data:\n",
    "\n",
    "            # Scelgo le key feature su cui voglio effettuare la suddivisione\n",
    "            key = (item['category'], item['place'], item['subject'])\n",
    "\n",
    "            # key = (item['category'], item['place'], item['subject'], item['brightness'], item['camera'])\n",
    "\n",
    "            # key = (item['camera'])\n",
    "\n",
    "            # key = ()\n",
    "\n",
    "            feature_groups[key].append(item)\n",
    "\n",
    "        train_data, val_data, test_data = [], [], []\n",
    "\n",
    "        for key, items in feature_groups.items():\n",
    "            total_items = len(items)\n",
    "            train_size = int(total_items * split_ratios[0])\n",
    "            val_size = int(total_items * split_ratios[1])\n",
    "\n",
    "            train_data.extend(items[:train_size])\n",
    "            val_data.extend(items[train_size:train_size + val_size])\n",
    "            test_data.extend(items[train_size + val_size:])\n",
    "\n",
    "        return train_data, val_data, test_data\n",
    "\n",
    "    train_data, val_data, test_data = split_data_by_feature(all_data, split_ratios)\n",
    "\n",
    "    splits = {\n",
    "        'train': train_data,\n",
    "        'val': val_data,\n",
    "        'test': test_data\n",
    "    }\n",
    "\n",
    "    for split, data in splits.items():\n",
    "        split_images_path = os.path.join(base_path, split, 'images')\n",
    "        split_labels_path = os.path.join(base_path, split, 'labels')\n",
    "        os.makedirs(split_images_path, exist_ok=True)\n",
    "        os.makedirs(split_labels_path, exist_ok=True)\n",
    "\n",
    "        for item in data:\n",
    "            category = item['category']\n",
    "            folder_name = item['folder']\n",
    "            frames_path = item['frames']\n",
    "            images = item['images']\n",
    "            labels = item['labels']\n",
    "\n",
    "            print(frames_path)\n",
    "\n",
    "            for img in images:\n",
    "                frame_number = img.split('.')[0].split('_')[-1]\n",
    "                new_image_name = f\"{category}_{folder_name}_frame_{frame_number}.jpg\"\n",
    "                src_img = os.path.join(frames_path, img)\n",
    "                dst_img = os.path.join(split_images_path, new_image_name)\n",
    "                shutil.copy(src_img, dst_img)\n",
    "\n",
    "            for lbl in labels:\n",
    "                frame_number = lbl.split('.')[0].split('_')[-1]\n",
    "                new_label_name = f\"{category}_{folder_name}_frame_{frame_number}.txt\"\n",
    "                src_lbl = os.path.join(frames_path, lbl)\n",
    "                dst_lbl = os.path.join(split_labels_path, new_label_name)\n",
    "                shutil.copy(src_lbl, dst_lbl)\n",
    "\n",
    "    print(\"Data split complete.\")\n",
    "    return splits\n",
    "\n",
    "def check_frames_in_same_split(splits):\n",
    "    folder_to_split = {}\n",
    "\n",
    "    for split, split_data in splits.items():\n",
    "        for item in split_data:\n",
    "            folder = item['folder']\n",
    "            if folder in folder_to_split:\n",
    "                print(f\"Error: Folder {folder} is present in both {folder_to_split[folder]} and {split}\")\n",
    "            else:\n",
    "                folder_to_split[folder] = split\n",
    "\n",
    "    print(\"Verification complete - every folder is assigned to one split.\")\n",
    "    # for folder, split in folder_to_split.items():\n",
    "    #    print(f\"Folder {folder} is correctly assigned to split {split}\")\n",
    "\n",
    "\n",
    "def check_balance(splits, feature):\n",
    "    total_counts = Counter()\n",
    "    split_counts = {'train': Counter(), 'val': Counter(), 'test': Counter()}\n",
    "\n",
    "    for split, data in splits.items():\n",
    "        for item in data:\n",
    "            key = item[feature]\n",
    "            total_counts[key] += len(item['images'])\n",
    "            split_counts[split][key] += len(item['images'])\n",
    "\n",
    "    print(f\"\\nBalancing based on {feature}:\")\n",
    "    total = sum(total_counts.values())\n",
    "    print(\n",
    "        f\"{'Feature':<20} {'Total':<10} {'Train':<10} {'Val':<10} {'Test':<10} {'Train %':<10} {'Val %':<10} {'Test %':<10}\")\n",
    "    print(\"-\" * 95)\n",
    "    for key in sorted(total_counts.keys()):\n",
    "        train_count = split_counts['train'][key]\n",
    "        val_count = split_counts['val'][key]\n",
    "        test_count = split_counts['test'][key]\n",
    "        train_percent = (train_count / total_counts[key]) * 100 if total_counts[key] > 0 else 0\n",
    "        val_percent = (val_count / total_counts[key]) * 100 if total_counts[key] > 0 else 0\n",
    "        test_percent = (test_count / total_counts[key]) * 100 if total_counts[key] > 0 else 0\n",
    "        print(\n",
    "            f\"{key:<20} {total_counts[key]:<10} {train_count:<10} {val_count:<10} {test_count:<10} {train_percent:<10.2f} {val_percent:<10.2f} {test_percent:<10.2f}\")"
   ],
   "id": "de55fb1f33ad6d43",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T09:06:09.597668Z",
     "start_time": "2024-06-04T09:04:25.684267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Utilizzo del codice\n",
    "base_path = './Gun_Action_Recognition_Dataset'\n",
    "split_ratios = (0.7, 0.2, 0.1)\n",
    "\n",
    "splits = split_dataset(base_path, split_ratios)"
   ],
   "id": "40149a77627572c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Gun_Action_Recognition_Dataset/Handgun/PCH2_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH1_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH8_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH2_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH3_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH6_C1_P1_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH5_C1_P1_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH5_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH2_C1_P1_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH7_C1_P1_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH1_C1_P1_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N12_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N6_C1_P1_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N2_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N11_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N10_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N4_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N3_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N7_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N1_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N12_C2_P5_V3_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N11_C2_P5_V3_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N10_C2_P5_V3_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N9_C2_P5_V3_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N3_C2_P5_V3_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N1_C2_P5_V3_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N7_C2_P5_V3_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH2_C1_P2_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH6_C1_P2_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH2_C1_P2_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH7_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH1_C1_P2_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH6_C1_P2_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH4_C1_P2_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH3_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH2_C1_P2_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH5_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH1_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH4_C1_P2_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH5_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH3_C1_P2_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH4_C2_P3_V2_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH4_C2_P3_V2_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH8_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH3_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH1_C2_P3_V2_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH7_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH5_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH7_C2_P3_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH6_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH2_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH3_C2_P3_V2_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH9_C2_P3_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH2_C2_P3_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH1_C2_P3_V2_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N4_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N7_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N8_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N8_C2_P3_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N10_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N1_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N2_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N6_C2_P3_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N3_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH5_C2_P5_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH1_C2_P5_V2_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH5_C2_P5_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH2_C2_P5_V2_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH3_C2_P5_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH7_C2_P5_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH2_C2_P5_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH9_C2_P5_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH2_C2_P5_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH3_C2_P5_V2_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH6_C2_P5_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH1_C2_P5_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH8_C2_P5_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH4_C2_P5_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH5_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH1_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH2_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH5_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH3_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH3_C1_P4_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH9_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH8_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH1_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH1_C1_P4_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH7_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH3_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH6_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N7_C2_P5_V4_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N5_C2_P5_V4_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N3_C2_P5_V4_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N6_C2_P5_V4_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N10_C2_P5_V4_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N9_C2_P5_V4_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N11_C2_P5_V4_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH2_C2_P5_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH6_C2_P5_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH5_C2_P5_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH7_C2_P5_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH5_C2_P5_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH9_C2_P5_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH4_C2_P5_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH2_C2_P5_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH3_C2_P5_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH8_C2_P5_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH1_C2_P5_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH2_C2_P5_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH3_C2_P5_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH4_C2_P5_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH6_C2_P5_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW4_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW2_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW9_C1_P4_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW9_C1_P4_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW1_C1_P4_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW1_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW2_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW4_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW6_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW5_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW5_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW6_C1_P2_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW4_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C1_P2_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW4_C1_P2_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW1_C1_P2_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW2_C1_P2_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW8_C1_P2_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW9_C1_P2_V1_HB_8/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW1_C1_P2_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW7_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW1_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW8_C1_P2_V1_HB_5/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW4_C1_P2_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW5_C1_P2_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW1_C1_P2_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW9_C1_P2_V1_HB_5/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW2_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C1_P2_V1_HB_7/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW8_C1_P2_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C1_P2_V1_HB_8/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW5_C1_P2_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW9_C1_P2_V1_HB_6/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW2_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW8_C2_P3_V2_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW9_C2_P3_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW9_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW1_C2_P3_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C2_P3_V2_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW4_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW8_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW5_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW2_C2_P3_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW1_C2_P3_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW7_C2_P3_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N12_C2_P5_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N6_C2_P5_V2_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N12_C2_P5_V2_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N10_C2_P5_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N5_C2_P5_V2_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N2_C2_P5_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N11_C2_P5_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N5_C2_P5_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N9_C2_P5_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N6_C2_P5_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW8_C2_P5_V3_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW7_C2_P5_V3_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW4_C2_P5_V3_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW6_C2_P5_V3_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW5_C2_P5_V3_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C2_P5_V3_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW2_C2_P5_V3_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW2_C2_P5_V3_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW5_C2_P5_V3_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW7_C1_P1_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW5_C1_P1_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW1_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW1_C1_P1_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW7_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW6_C1_P1_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW8_C1_P1_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW2_C1_P1_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW9_C1_P1_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW1_C1_P1_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW4_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW5_C1_P1_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW2_C1_P1_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW5_C1_P1_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW1_C1_P1_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW4_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW8_C1_P1_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C2_P5_V4_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW4_C2_P5_V4_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW2_C2_P5_V4_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C2_P5_V4_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW2_C2_P5_V4_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW7_C2_P5_V4_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW4_C2_P5_V4_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW1_C2_P5_V4_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW5_C2_P5_V4_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N8_C1_P2_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N7_C1_P2_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N11_C1_P2_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N3_C1_P2_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N8_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N2_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N9_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N12_C1_P2_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N4_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N5_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH2_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH1_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH1_C2_P3_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH7_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH3_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH6_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH3_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH1_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH7_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH6_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH3_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH2_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH4_C2_P3_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH5_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW1_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW1_C2_P3_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW2_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW1_C2_P3_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW4_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW6_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW9_C2_P3_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW2_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW8_C2_P3_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW7_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N8_C1_P4_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N12_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N8_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N6_C1_P4_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N10_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N4_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N9_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N6_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N11_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N7_C2_P3_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N8_C2_P3_V2_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N8_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N6_C2_P3_V2_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N2_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N9_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N11_C2_P3_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N1_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N6_C2_P5_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N1_C2_P5_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N8_C2_P5_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N8_C2_P5_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N6_C2_P5_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N5_C2_P5_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N12_C2_P5_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N5_C2_P5_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N3_C2_P5_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH7_C1_P1_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH1_C1_P1_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH3_C1_P1_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N8_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N5_C1_P1_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N8_C2_P5_V3_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N6_C2_P5_V3_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH1_C1_P2_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH4_C1_P2_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH7_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH8_C1_P2_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH3_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH1_C2_P3_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH5_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH4_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N11_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N6_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH1_C2_P5_V2_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH1_C2_P5_V2_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH3_C2_P5_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH4_C2_P5_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH4_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH2_C1_P4_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH2_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N2_C2_P5_V4_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N1_C2_P5_V4_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH1_C2_P5_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH1_C2_P5_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH4_C2_P5_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH3_C2_P5_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW1_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW7_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW8_C1_P4_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW6_C1_P2_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW5_C1_P2_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW9_C1_P2_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW2_C1_P2_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW7_C1_P2_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW4_C1_P2_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW2_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW6_C2_P3_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW5_C2_P3_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N3_C2_P5_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N8_C2_P5_V2_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N4_C2_P5_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C2_P5_V3_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW9_C2_P5_V3_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW5_C1_P1_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW4_C1_P1_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW2_C1_P1_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C1_P1_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C1_P1_V1_HB_7/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW1_C2_P5_V4_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW8_C2_P5_V4_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N6_C1_P2_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N12_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N1_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH2_C2_P3_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH4_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH9_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH5_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW9_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW5_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW4_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N1_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N7_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N4_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N6_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N4_C2_P5_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N11_C2_P5_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH6_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH4_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH3_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N9_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N6_C1_P1_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N5_C2_P5_V3_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N2_C2_P5_V3_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH1_C1_P2_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH3_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH6_C2_P3_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH2_C2_P3_V2_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH1_C2_P3_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N9_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N12_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH7_C2_P5_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH6_C2_P5_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH4_C2_P5_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH6_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH1_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH4_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N12_C2_P5_V4_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N8_C2_P5_V4_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH9_C2_P5_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH1_C2_P5_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH7_C2_P5_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW8_C1_P4_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C1_P4_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C1_P2_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW8_C1_P2_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW5_C1_P2_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW1_C1_P2_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW4_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW1_C2_P3_V2_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N8_C2_P5_V2_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N1_C2_P5_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW4_C2_P5_V3_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW1_C2_P5_V3_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW1_C2_P5_V3_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW4_C1_P1_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW9_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW2_C1_P1_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C1_P1_V1_HB_8/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW9_C2_P5_V4_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW6_C2_P5_V4_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW5_C2_P5_V4_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N6_C1_P2_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N10_C1_P2_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PCH1_C2_P3_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH4_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Handgun/PAH8_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW5_C2_P3_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PAW8_C2_P3_V1_HB_3/frames\n",
      "./Gun_Action_Recognition_Dataset/Machine_Gun/PCW8_C2_P3_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N5_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N5_C1_P4_V1_HB_4/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N2_C1_P4_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N10_C2_P3_V2_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N3_C2_P3_V2_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N9_C2_P5_V1_HB_2/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N10_C2_P5_V1_HB_1/frames\n",
      "./Gun_Action_Recognition_Dataset/No_Gun/N2_C2_P5_V1_HB_1/frames\n",
      "Data split complete.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T09:15:56.232998Z",
     "start_time": "2024-06-04T09:15:56.105428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Scelgo di quali categorie voglio visualizzare il bilanciamento\n",
    "check_frames_in_same_split(splits)\n",
    "check_balance(splits, 'category')\n",
    "check_balance(splits, 'place')\n",
    "check_balance(splits, 'subject')\n",
    "# check_balance(splits, 'brightness')\n",
    "# check_balance(splits, 'camera')"
   ],
   "id": "efc5702553e039c4",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'splits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Scelgo di quali categorie voglio visualizzare il bilanciamento\u001B[39;00m\n\u001B[1;32m      2\u001B[0m base_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./Gun_Action_Recognition_Dataset\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 3\u001B[0m check_frames_in_same_split(\u001B[43msplits\u001B[49m)\n\u001B[1;32m      4\u001B[0m check_balance(splits, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategory\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      5\u001B[0m check_balance(splits, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mplace\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'splits' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T09:16:27.350361Z",
     "start_time": "2024-06-04T09:16:27.348126Z"
    }
   },
   "cell_type": "code",
   "source": "yaml_filename = 'guns_dataset.yaml'",
   "id": "ccce3be7cc1f3851",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T09:06:37.045678Z",
     "start_time": "2024-06-04T09:06:36.478491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_dataset_structure(base_path):\n",
    "    splits = ['train', 'val', 'test']\n",
    "    for split in splits:\n",
    "        images_dir = os.path.join(base_path, split, 'images')\n",
    "        labels_dir = os.path.join(base_path, split, 'labels')\n",
    "\n",
    "        if not os.path.exists(images_dir) or not os.path.exists(labels_dir):\n",
    "            print(f\"Error: {images_dir} or {labels_dir} does not exist.\")\n",
    "            return False\n",
    "        \n",
    "        images = set(os.listdir(images_dir))\n",
    "        labels = set(os.listdir(labels_dir))\n",
    "        \n",
    "        if len(images) == 0 or len(labels) == 0:\n",
    "            print(f\"Error: {split} set is empty.\")\n",
    "            return False\n",
    "        \n",
    "        image_names = set(os.path.splitext(img)[0] for img in images)\n",
    "        label_names = set(os.path.splitext(lbl)[0] for lbl in labels)\n",
    "\n",
    "        # Find images that have corresponding labels\n",
    "        images_with_labels = image_names & label_names\n",
    "        # Find images without labels (which is acceptable in this dataset)\n",
    "        images_without_labels = image_names - label_names\n",
    "        # Find labels without corresponding images (which is an error)\n",
    "        labels_without_images = label_names - image_names\n",
    "\n",
    "        if labels_without_images:\n",
    "            print(f\"Error: There are labels without corresponding images in {split} set.\")\n",
    "            print(f\"Labels without images: {sorted(labels_without_images)}\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"{split.capitalize()} set is correctly structured.\")\n",
    "        print(f\"Total images: {len(images)} (with labels: {len(images_with_labels)}, without labels: {len(images_without_labels)})\")\n",
    "        print(f\"Total labels: {len(labels)}\")\n",
    "        print(\"-------------------------------------------------------------\")\n",
    "\n",
    "    return True\n",
    "\n",
    "# Verifica la struttura del dataset\n",
    "dataset_base_path = '/Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset'\n",
    "if check_dataset_structure(dataset_base_path):\n",
    "    print(\"Dataset structure is correct.\")\n",
    "else:\n",
    "    print(\"Dataset structure has issues.\")"
   ],
   "id": "ae83d6fad009c6ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set is correctly structured.\n",
      "Total images: 66795 (with labels: 28711, without labels: 38084)\n",
      "Total labels: 28711\n",
      "-------------------------------------------------------------\n",
      "Val set is correctly structured.\n",
      "Total images: 17165 (with labels: 7360, without labels: 9805)\n",
      "Total labels: 7360\n",
      "-------------------------------------------------------------\n",
      "Test set is correctly structured.\n",
      "Total images: 15755 (with labels: 6859, without labels: 8896)\n",
      "Total labels: 6859\n",
      "-------------------------------------------------------------\n",
      "Dataset structure is correct.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.28 ð Python-3.12.3 torch-2.3.0 MPS (Apple M1 Pro)\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov8n.pt, data=guns_dataset.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=mps, workers=8, project=None, name=train12, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train12\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011238 parameters, 3011222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train12', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/train/labels.cache... 66095 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 66095/66095 [00:00<?, ?it/s]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/val/labels.cache... 17965 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 17965/17965 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train12/labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added â\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1mruns/detect/train12\u001B[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      2.484      11.39      1.727          9        640:   4%|â         | 166/4131 [04:59<1:59:24,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during training: Trying to create tensor with negative dimension -1: [16, -1, 5]\n",
      "Checking the problematic batch...\n",
      "Saved annotated image to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1/Handgun_PAH9_C2_P3_V2_HB_2_frame_0090.jpg\n",
      "Saved annotated image to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1/Machine_Gun_PCW1_C2_P3_V2_HB_2_frame_0143.jpg\n",
      "Saved annotated image to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1/Machine_Gun_PAW1_C2_P3_V1_HB_2_frame_0276.jpg\n",
      "Saved annotated image to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1/Machine_Gun_PAW4_C1_P1_V1_HB_2_frame_0151.jpg\n",
      "Saved annotated image to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1/Machine_Gun_PAW8_C1_P2_V1_HB_8_frame_0266.jpg\n",
      "Saved annotated image to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1/Machine_Gun_PAW8_C1_P1_V1_HB_1_frame_0058.jpg\n",
      "Saved annotated image to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1/No_Gun_N9_C1_P2_V1_HB_1_frame_0139.jpg\n",
      "Saved annotated image to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1/Machine_Gun_PAW8_C2_P5_V4_HB_3_frame_0285.jpg\n",
      "Saved annotated image to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1/Handgun_PCH4_C1_P4_V1_HB_2_frame_0130.jpg\n",
      "Saved annotated image to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1/No_Gun_N8_C2_P3_V1_HB_4_frame_0167.jpg\n",
      "Saved annotated image to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1/No_Gun_N8_C2_P3_V2_HB_3_frame_0199.jpg\n",
      "Saved annotated image to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1/Handgun_PCH4_C2_P5_V1_HB_2_frame_0071.jpg\n",
      "Saved annotated image to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1/Handgun_PAH4_C2_P3_V2_HB_4_frame_0086.jpg\n",
      "Saved annotated image to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1/Handgun_PAH2_C2_P5_V1_HB_4_frame_0286.jpg\n",
      "Saved annotated image to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1/Handgun_PCH1_C2_P5_V2_HB_2_frame_0166.jpg\n",
      "Saved annotated image to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1/Handgun_PCH7_C1_P2_V1_HB_1_frame_0084.jpg\n",
      "Saved problematic batch to /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/problematic_batches/batch_1.\n"
     ]
    }
   ],
   "execution_count": 8,
   "source": [
    "# GPU\n",
    "\n",
    "# Funzione personalizzata per il training\n",
    "def custom_train(model, yaml_filename, epochs=10, batch_size=16, imgsz=480, device = \"mps\"):\n",
    "    problematic_batches_dir = os.path.join(base_path, 'problematic_batches')\n",
    "    os.makedirs(problematic_batches_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Esegui il training per il numero totale di epoche specificato\n",
    "        model.train(data=yaml_filename, epochs=epochs, batch=batch_size, device = device, imgsz=imgsz, verbose=True)\n",
    "    except RuntimeError as e:\n",
    "        if 'negative dimension' in str(e):\n",
    "            print(f\"Error during training: {e}\")\n",
    "            print(\"Checking the problematic batch...\")\n",
    "\n",
    "            # Verifica ogni file del batch problematico\n",
    "            image_folder = os.path.join(base_path, 'train', 'images')\n",
    "            label_folder = os.path.join(base_path, 'train', 'labels')\n",
    "\n",
    "            problematic_images = os.listdir(image_folder)[:batch_size]  # Prende un batch di immagini\n",
    "\n",
    "            # Crea una cartella per salvare le immagini annotate\n",
    "            save_dir = os.path.join(problematic_batches_dir, 'batch_1')\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "            for image_file in problematic_images:\n",
    "                image_path = os.path.join(image_folder, image_file)\n",
    "                label_path = os.path.join(label_folder, image_file.replace('.jpg', '.txt'))\n",
    "\n",
    "                # Copia l'immagine e il file di etichetta nella cartella dei batch problematici\n",
    "                shutil.copy(image_path, save_dir)\n",
    "                shutil.copy(label_path, save_dir)\n",
    "\n",
    "                verify_and_fix_image_and_label(image_path, label_path)\n",
    "                display_and_save_image_with_annotations(image_path, label_path, save_dir)\n",
    "\n",
    "            print(f\"Saved problematic batch to {save_dir}.\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "# Esegui il training personalizzato\n",
    "custom_train(model, yaml_filename, epochs=10, batch_size=16, imgsz=640, device = \"mps\")"
   ],
   "id": "70e8380321e1cd22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T09:20:16.937860Z",
     "start_time": "2024-06-04T09:16:32.159200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CPU\n",
    "\n",
    "# Inizializza il modello YOLO\n",
    "model = YOLO('basic_models/yolov8n.pt')\n",
    "\n",
    "# Funzione personalizzata per il training\n",
    "def custom_train(model, yaml_filename, epochs=10, batch_size=16, imgsz=480):\n",
    "    problematic_batches_dir = os.path.join(base_path, 'problematic_batches')\n",
    "    os.makedirs(problematic_batches_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Esegui il training per il numero totale di epoche specificato\n",
    "        model.train(data=yaml_filename, epochs=epochs, batch=batch_size, imgsz=imgsz, verbose=True)\n",
    "    except RuntimeError as e:\n",
    "        if 'negative dimension' in str(e):\n",
    "            print(f\"Error during training: {e}\")\n",
    "            print(\"Checking the problematic batch...\")\n",
    "\n",
    "            # Verifica ogni file del batch problematico\n",
    "            image_folder = os.path.join(base_path, 'train', 'images')\n",
    "            label_folder = os.path.join(base_path, 'train', 'labels')\n",
    "\n",
    "            problematic_images = os.listdir(image_folder)[:batch_size]  # Prende un batch di immagini\n",
    "\n",
    "            # Crea una cartella per salvare le immagini annotate\n",
    "            save_dir = os.path.join(problematic_batches_dir, 'batch_1')\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "            for image_file in problematic_images:\n",
    "                image_path = os.path.join(image_folder, image_file)\n",
    "                label_path = os.path.join(label_folder, image_file.replace('.jpg', '.txt'))\n",
    "\n",
    "                # Copia l'immagine e il file di etichetta nella cartella dei batch problematici\n",
    "                shutil.copy(image_path, save_dir)\n",
    "                shutil.copy(label_path, save_dir)\n",
    "\n",
    "                verify_and_fix_image_and_label(image_path, label_path)\n",
    "                display_and_save_image_with_annotations(image_path, label_path, save_dir)\n",
    "\n",
    "            print(f\"Saved problematic batch to {save_dir}.\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "# Esegui il training personalizzato\n",
    "custom_train(model, yaml_filename, epochs=10, batch_size=16, imgsz=640)"
   ],
   "id": "340931eff34b0b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.28 ð Python-3.12.3 torch-2.3.0 CPU (Apple M1 Pro)\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov8n.pt, data=guns_dataset.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train7\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011238 parameters, 3011222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train7', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/train/labels... 28711 images, 38084 backgrounds, 0 corrupt: 100%|ââââââââââ| 66795/66795 [00:19<00:00, 3423.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/val/labels... 7360 images, 9805 backgrounds, 0 corrupt: 100%|ââââââââââ| 17165/17165 [00:04<00:00, 3588.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: /Users/andreavisi/Desktop/PYTHON/Computer Vision e Deep Learning 2024/PROGETTO/Gun_Action_Recognition_Dataset/val/labels.cache\n",
      "Plotting labels to runs/detect/train7/labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added â\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1mruns/detect/train7\u001B[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G       3.32      16.58        2.3          8        640:   0%|          | 14/4175 [02:41<13:21:41, 11.56s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 45\u001B[0m\n\u001B[1;32m     42\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m     44\u001B[0m \u001B[38;5;66;03m# Esegui il training personalizzato\u001B[39;00m\n\u001B[0;32m---> 45\u001B[0m \u001B[43mcustom_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43myaml_filename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimgsz\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m640\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[8], line 13\u001B[0m, in \u001B[0;36mcustom_train\u001B[0;34m(model, yaml_filename, epochs, batch_size, imgsz)\u001B[0m\n\u001B[1;32m      9\u001B[0m os\u001B[38;5;241m.\u001B[39mmakedirs(problematic_batches_dir, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;66;03m# Esegui il training per il numero totale di epoche specificato\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43myaml_filename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimgsz\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimgsz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnegative dimension\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e):\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ultralytics/engine/model.py:674\u001B[0m, in \u001B[0;36mModel.train\u001B[0;34m(self, trainer, **kwargs)\u001B[0m\n\u001B[1;32m    671\u001B[0m             \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mhub_session \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession  \u001B[38;5;66;03m# attach optional HUB session\u001B[39;00m\n\u001B[0;32m--> 674\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[38;5;66;03m# Update model and cfg after training\u001B[39;00m\n\u001B[1;32m    676\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m RANK \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m}:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ultralytics/engine/trainer.py:199\u001B[0m, in \u001B[0;36mBaseTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    196\u001B[0m         ddp_cleanup(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mstr\u001B[39m(file))\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 199\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mworld_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ultralytics/engine/trainer.py:371\u001B[0m, in \u001B[0;36mBaseTrainer._do_train\u001B[0;34m(self, world_size)\u001B[0m\n\u001B[1;32m    369\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mamp):\n\u001B[1;32m    370\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess_batch(batch)\n\u001B[0;32m--> 371\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_items \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    372\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m RANK \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    373\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m world_size\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ultralytics/nn/tasks.py:88\u001B[0m, in \u001B[0;36mBaseModel.forward\u001B[0;34m(self, x, *args, **kwargs)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;124;03mForward pass of the model on a single scale. Wrapper for `_forward_once` method.\u001B[39;00m\n\u001B[1;32m     80\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;124;03m    (torch.Tensor): The output of the network.\u001B[39;00m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mdict\u001B[39m):  \u001B[38;5;66;03m# for cases of training and validating while training.\u001B[39;00m\n\u001B[0;32m---> 88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ultralytics/nn/tasks.py:266\u001B[0m, in \u001B[0;36mBaseModel.loss\u001B[0;34m(self, batch, preds)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcriterion\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    264\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcriterion \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_criterion()\n\u001B[0;32m--> 266\u001B[0m preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mimg\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m preds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m preds\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcriterion(preds, batch)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ultralytics/nn/tasks.py:89\u001B[0m, in \u001B[0;36mBaseModel.forward\u001B[0;34m(self, x, *args, **kwargs)\u001B[0m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mdict\u001B[39m):  \u001B[38;5;66;03m# for cases of training and validating while training.\u001B[39;00m\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss(x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 89\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ultralytics/nn/tasks.py:107\u001B[0m, in \u001B[0;36mBaseModel.predict\u001B[0;34m(self, x, profile, visualize, augment, embed)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m augment:\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_predict_augment(x)\n\u001B[0;32m--> 107\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predict_once\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprofile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvisualize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membed\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ultralytics/nn/tasks.py:128\u001B[0m, in \u001B[0;36mBaseModel._predict_once\u001B[0;34m(self, x, profile, visualize, embed)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m profile:\n\u001B[1;32m    127\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_profile_one_layer(m, x, dt)\n\u001B[0;32m--> 128\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# run\u001B[39;00m\n\u001B[1;32m    129\u001B[0m y\u001B[38;5;241m.\u001B[39mappend(x \u001B[38;5;28;01mif\u001B[39;00m m\u001B[38;5;241m.\u001B[39mi \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)  \u001B[38;5;66;03m# save output\u001B[39;00m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m visualize:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ultralytics/nn/modules/block.py:231\u001B[0m, in \u001B[0;36mC2f.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    229\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv1(x)\u001B[38;5;241m.\u001B[39mchunk(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m    230\u001B[0m y\u001B[38;5;241m.\u001B[39mextend(m(y[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mm)\n\u001B[0;32m--> 231\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcv2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ultralytics/nn/modules/conv.py:50\u001B[0m, in \u001B[0;36mConv.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     49\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 50\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mact(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m))\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
